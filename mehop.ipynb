{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gc\n",
    "import psutil\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMORY_LIMIT = 7 * 1024 * 1024 * 1024\n",
    "total_memory = psutil.virtual_memory().total / (1024**3)\n",
    "print(f\"Total system memory: {total_memory:.2f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_memory():\n",
    "    \"\"\"Check if memory usage is approaching limit\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_use = process.memory_info().rss\n",
    "    if memory_use > MEMORY_LIMIT:\n",
    "        raise MemoryError(f\"Memory usage ({memory_use / 1024**3:.2f}GB) exceeded limit of 7GB\")\n",
    "    return memory_use\n",
    "\n",
    "def log_memory_usage(tag=\"\"):\n",
    "    \"\"\"Log current memory usage\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_use = process.memory_info().rss\n",
    "    print(f\"Memory usage {tag}: {memory_use / 1024**3:.2f}GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path = self.df.iloc[idx]['FilePath']\n",
    "            label = self.df.iloc[idx]['Label']\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            check_memory()  # Check memory usage\n",
    "            return image, label, idx\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image at index {idx}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_folder_to_dataframe(base_folder):\n",
    "    print(\"scan folder to dataframe\")\n",
    "    check_memory()\n",
    "    data = [(os.path.join(root, file), os.path.basename(root))\n",
    "            for root, _, files in os.walk(base_folder)\n",
    "            for file in files]\n",
    "    df = pd.DataFrame(data, columns=['FilePath', 'Label'])\n",
    "    log_memory_usage(\"after DataFrame creation\")\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features_increment(features_dict, output_file):\n",
    "    print(\"save_features_increment\")\n",
    "    \"\"\"Save features incrementally to avoid memory buildup\"\"\"\n",
    "    check_memory()\n",
    "    \n",
    "    \n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, 'rb') as f:\n",
    "            existing_dict = pickle.load(f)\n",
    "        existing_dict.update(features_dict)\n",
    "        features_dict = existing_dict\n",
    "    \n",
    "    with open(output_file, 'wb') as f:\n",
    "        pickle.dump(features_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_batch(model, dataloader, device, output_file, batch_size=32):\n",
    "    print(\"extract_features_batch\")\n",
    "    \"\"\"Extract features in batches and save incrementally to avoid memory buildup\"\"\"\n",
    "    model.eval()\n",
    "    features_dict = {}\n",
    "    total_processed = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_imgs, batch_labels, batch_indices in dataloader:\n",
    "            check_memory()\n",
    "            \n",
    "            # Skip None values from failed loads\n",
    "            if batch_imgs is None:\n",
    "                continue\n",
    "                \n",
    "            batch_imgs = batch_imgs.to(device)\n",
    "            \n",
    "            # Extract features\n",
    "            features = model(batch_imgs)\n",
    "            features = features.cpu().numpy()\n",
    "            \n",
    "            # Store features and free memory\n",
    "            for idx, (label, feature) in enumerate(zip(batch_labels, features)):\n",
    "                original_idx = batch_indices[idx].item()\n",
    "                features_dict[original_idx] = {\n",
    "                    'label': label,\n",
    "                    'features': feature\n",
    "                }\n",
    "            \n",
    "            # Clear GPU memory\n",
    "            del batch_imgs, features\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "            \n",
    "            total_processed += batch_size\n",
    "            \n",
    "            # Save more frequently to manage memory\n",
    "            if len(features_dict) >= 500:  # Reduced from 1000 to 500\n",
    "                save_features_increment(features_dict, output_file)\n",
    "                features_dict.clear()\n",
    "                gc.collect()\n",
    "            \n",
    "            log_memory_usage(f\"after processing {total_processed} images\")\n",
    "    \n",
    "    # Save any remaining features\n",
    "    if features_dict:\n",
    "        save_features_increment(features_dict, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_from_features(feature_file_path, graph_file_path, batch_size=500):  # Reduced batch size\n",
    "    \"\"\"Build graph in batches to reduce memory usage\"\"\"\n",
    "    print(\"build graph from features\")\n",
    "    check_memory()\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    with open(feature_file_path, 'rb') as f:\n",
    "        features_dict = pickle.load(f)\n",
    "    \n",
    "    # Add nodes first\n",
    "    for index, data in features_dict.items():\n",
    "        G.add_node(index, label=data['label'])\n",
    "    \n",
    "    # Process edges in batches\n",
    "    nodes = list(G.nodes())\n",
    "    n_nodes = len(nodes)\n",
    "    total_processed = 0\n",
    "    \n",
    "    for i in range(0, n_nodes, batch_size):\n",
    "        check_memory()\n",
    "        \n",
    "        batch_nodes = nodes[i:i + batch_size]\n",
    "        batch_features = np.array([features_dict[node]['features'] for node in batch_nodes])\n",
    "        \n",
    "        for j in range(i, n_nodes, batch_size):\n",
    "            other_nodes = nodes[j:j + batch_size]\n",
    "            other_features = np.array([features_dict[node]['features'] for node in other_nodes])\n",
    "            \n",
    "            # Calculate similarities using matrix operations\n",
    "            similarities = batch_features @ other_features.T\n",
    "            norms_1 = np.linalg.norm(batch_features, axis=1)\n",
    "            norms_2 = np.linalg.norm(other_features, axis=1)\n",
    "            similarities = similarities / np.outer(norms_1, norms_2)\n",
    "            \n",
    "            # Add edges for high similarities\n",
    "            for idx1, node1 in enumerate(batch_nodes):\n",
    "                for idx2, node2 in enumerate(other_nodes[idx1:], idx1):\n",
    "                    if similarities[idx1, idx2] > 0.5:\n",
    "                        G.add_edge(node1, node2, weight=float(similarities[idx1, idx2]))\n",
    "            \n",
    "            del other_features\n",
    "            gc.collect()\n",
    "        \n",
    "        total_processed += len(batch_nodes)\n",
    "        log_memory_usage(f\"after processing {total_processed}/{n_nodes} nodes\")\n",
    "        \n",
    "        del batch_features\n",
    "        gc.collect()\n",
    "    \n",
    "    # Save the graph\n",
    "    with open(graph_file_path, 'wb') as f:\n",
    "        pickle.dump(G, f)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(base_folder, batch_size=16):  # Reduced default batch size\n",
    "    print(\"main fn\")\n",
    "    try:\n",
    "        # Initialize memory logging\n",
    "        log_memory_usage(\"start\")\n",
    "        \n",
    "        # Create dataset\n",
    "        dataset = scan_folder_to_dataframe(base_folder)\n",
    "        train_set, test_set = train_test_split(dataset, test_size=0.2, stratify=dataset['Label'], random_state=42)\n",
    "        \n",
    "        # Setup data loading\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        \n",
    "        train_dataset = ImageDataset(train_set, transform=transform)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Setup model\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = resnet50(pretrained=True).to(device)\n",
    "        \n",
    "        # Extract features\n",
    "        feature_file = \"features.pkl\"\n",
    "        extract_features_batch(model, train_loader, device, feature_file, batch_size)\n",
    "        \n",
    "        # Clear some memory before graph construction\n",
    "        del model\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        gc.collect()\n",
    "        \n",
    "        # Build graph\n",
    "        graph_file = \"graph.pkl\"\n",
    "        G = build_graph_from_features(feature_file, graph_file)\n",
    "        \n",
    "        log_memory_usage(\"end\")\n",
    "        return G\n",
    "        \n",
    "    except MemoryError as e:\n",
    "        print(f\"Memory limit exceeded: {str(e)}\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aydhi\\OneDrive\\Documents\\capstone\\TRY2\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aydhi\\OneDrive\\Documents\\capstone\\TRY2\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'networkx' has no attribute 'write_gpickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m     base_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlung_image_sets\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m     G \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 26\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(base_folder, batch_size)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Build graph\u001b[39;00m\n\u001b[0;32m     25\u001b[0m graph_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 26\u001b[0m G \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_graph_from_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m G\n",
      "Cell \u001b[1;32mIn[6], line 43\u001b[0m, in \u001b[0;36mbuild_graph_from_features\u001b[1;34m(feature_file_path, graph_file_path, batch_size)\u001b[0m\n\u001b[0;32m     40\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Save the graph\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_gpickle\u001b[49m(G, graph_file_path)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m G\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'networkx' has no attribute 'write_gpickle'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    base_folder = \"lung_image_sets\"\n",
    "    G = main(base_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
