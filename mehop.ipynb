{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['FilePath']\n",
    "        label = self.df.iloc[idx]['Label']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_folder_to_dataframe(base_folder):\n",
    "    data = [(os.path.join(root, file), os.path.basename(root))\n",
    "            for root, _, files in os.walk(base_folder)\n",
    "            for file in files]\n",
    "    return pd.DataFrame(data, columns=['FilePath', 'Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features_increment(features_dict, output_file):\n",
    "    \"\"\"Save features incrementally to avoid memory buildup\"\"\"\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, 'rb') as f:\n",
    "            existing_dict = pickle.load(f)\n",
    "        existing_dict.update(features_dict)\n",
    "        features_dict = existing_dict\n",
    "    \n",
    "    with open(output_file, 'wb') as f:\n",
    "        pickle.dump(features_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_batch(model, dataloader, device, output_file, batch_size=32):\n",
    "    \"\"\"Extract features in batches and save incrementally to avoid memory buildup\"\"\"\n",
    "    model.eval()\n",
    "    features_dict = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_imgs, batch_labels, batch_indices in dataloader:\n",
    "            batch_imgs = batch_imgs.to(device)\n",
    "            \n",
    "            # Extract features\n",
    "            features = model(batch_imgs)\n",
    "            features = features.cpu().numpy()\n",
    "            \n",
    "            # Store features and free memory\n",
    "            for idx, (label, feature) in enumerate(zip(batch_labels, features)):\n",
    "                original_idx = batch_indices[idx].item()\n",
    "                features_dict[original_idx] = {\n",
    "                    'label': label,\n",
    "                    'features': feature\n",
    "                }\n",
    "            \n",
    "            # Clear GPU memory\n",
    "            del batch_imgs, features\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "            \n",
    "            # Incrementally save to disk if dictionary gets too large\n",
    "            if len(features_dict) >= 1000:\n",
    "                save_features_increment(features_dict, output_file)\n",
    "                features_dict.clear()\n",
    "    \n",
    "    # Save any remaining features\n",
    "    if features_dict:\n",
    "        save_features_increment(features_dict, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_from_features(feature_file_path, graph_file_path, batch_size=1000):\n",
    "    \"\"\"Build graph in batches to reduce memory usage\"\"\"\n",
    "    # Load features in batches\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    with open(feature_file_path, 'rb') as f:\n",
    "        features_dict = pickle.load(f)\n",
    "    \n",
    "    # Add nodes first\n",
    "    for index, data in features_dict.items():\n",
    "        G.add_node(index, label=data['label'])\n",
    "    \n",
    "    # Process edges in batches\n",
    "    nodes = list(G.nodes())\n",
    "    n_nodes = len(nodes)\n",
    "    \n",
    "    for i in range(0, n_nodes, batch_size):\n",
    "        batch_nodes = nodes[i:i + batch_size]\n",
    "        batch_features = np.array([features_dict[node]['features'] for node in batch_nodes])\n",
    "        \n",
    "        # Calculate similarities for this batch with all other nodes\n",
    "        for j in range(i, n_nodes, batch_size):\n",
    "            other_nodes = nodes[j:j + batch_size]\n",
    "            other_features = np.array([features_dict[node]['features'] for node in other_nodes])\n",
    "            \n",
    "            # Calculate similarities using matrix operations\n",
    "            similarities = batch_features @ other_features.T\n",
    "            norms_1 = np.linalg.norm(batch_features, axis=1)\n",
    "            norms_2 = np.linalg.norm(other_features, axis=1)\n",
    "            similarities = similarities / np.outer(norms_1, norms_2)\n",
    "            \n",
    "            # Add edges for high similarities\n",
    "            for idx1, node1 in enumerate(batch_nodes):\n",
    "                for idx2, node2 in enumerate(other_nodes[idx1:], idx1):\n",
    "                    if similarities[idx1, idx2] > 0.5:\n",
    "                        G.add_edge(node1, node2, weight=float(similarities[idx1, idx2]))\n",
    "        \n",
    "        # Clear batch data\n",
    "        del batch_features\n",
    "        gc.collect()\n",
    "    \n",
    "    # Save the graph\n",
    "    nx.write_gpickle(G, graph_file_path)\n",
    "    print(f\"Graph saved to {graph_file_path}\")\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(base_folder, batch_size=32):\n",
    "    # Create dataset\n",
    "    dataset = scan_folder_to_dataframe(base_folder)\n",
    "    train_set, test_set = train_test_split(dataset, test_size=0.2, stratify=dataset['Label'], random_state=42)\n",
    "    \n",
    "    # Setup data loading\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    train_dataset = ImageDataset(train_set, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Setup model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = resnet50(pretrained=True).to(device)\n",
    "    \n",
    "    # Extract features\n",
    "    feature_file = \"features.pkl\"\n",
    "    extract_features_batch(model, train_loader, device, feature_file, batch_size)\n",
    "    \n",
    "    # Build graph\n",
    "    graph_file = \"graph.pkl\"\n",
    "    G = build_graph_from_features(feature_file, graph_file)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aydhi\\OneDrive\\Documents\\capstone\\TRY2\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aydhi\\OneDrive\\Documents\\capstone\\TRY2\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    base_folder = \"lung_image_sets\"\n",
    "    G = main(base_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
